---
title: 数据结构与算法之美 Notes
categories: Geek
photos: https://cdn.jsdelivr.net/gh/Casuor/CDN@latest/Posts/Image/Common/xiangxiang.jpg
date: 2018-8-23
---
## 数据结构与算法之美-王争

推动算法传播的是生活在美索不达米亚的AI Khwarizmi 于9世纪一本以阿拉姆语著述的教科书。

### 一、目标

**什么是数据结构？什么是算法？**

从广义上讲，数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。

从狭义上讲，也就是我们专栏要讲的，是指某些著名的数据结构和算法，比如队列、栈、堆、二分
查找、动态规划等。这些都是前人智慧的结晶，我们可以直接拿来用。

**数据结构与算法的关系？**

这是因为，数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结
构之上。   因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。

> 比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选
> 择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。

数据结构是静态的，它只是组织数据的一种方式。如果不在它的基础上操作、构建算法，孤立存在
的数据结构就是没用的。

**学习的重点？**

复杂度分析

数据结构和算法解决的是如何更省、更快地存储和处理数据的问题，因此，我们就需要一个考量效率和

资源消耗的方法，这就是复杂度分析方法。所以，只掌握了数据结构和算法的特点、用法，但是没有学

会复杂度分析，那就相当于只知道操作口诀，而没掌握心法。只有把心法了然于胸，才能做到无招胜有招！

**常用的，基础的数据结构与算法**

 10  个数据结构：

数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、 Trie  树； 

10个算法：

递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

------

### 二、算法复杂度分析

**如何分析、统计算法的执行效率和资源消耗？**

时间、空间复杂度分析。
**为什么需要复杂度分析？**

> 你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大
> 小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比我实实在在跑一遍得到的数据更准
> 确吗？
> 首先，我可以肯定地说，你这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给
> 这种方法起了一个名字，叫事后统计法。但是，这种统计方法有非常大的局限性。

1.测试结果非常依赖测试环境。

2.测试结果受数据规模影响很大

3.大O复杂度表示法


    int cal(int n) {
      int sum = 0;
      int i = 1;
      for (; i <= n; ++i) {
        sum = sum + i;
      }
      return sum;
    }


> 从  CPU  的角度来看，这段代码的每一行都执行着类似的操作：读数据 - 运算 - 写数据。尽管每行代码
> 对应的  CPU  执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每
> 行代码执行的时间都一样，为  unit_time 。在这个假设的基础之上，这段代码的总执行时间是多少
> 呢？
> 第  2 、 3  行代码分别需要  1  个  unit_time  的执行时间，第  4 、 5  行都运行了  n  遍，所以需要
> 2nunit_time  的执行时间，所以这段代码总的执行时间就是  (2n+2)*unit_time 。可以看出来，所有代
> 码的执行时间  T(n)  与每行代码的执行次数成正比。

按照这个分析思路，我们再来看这段代码。


    int cal(int n) {
      int sum = 0;
      int i = 1;
      int j = 1;
      for (; i <= n; ++i) {
        j = 1;
        for (; j <= n; ++j) {
          sum = sum +  i * j;
        }
      }
    }


> 我们依旧假设每个语句的执行时间是  unit_time 。那这段代码的总执行时间  T(n)  是多少呢？
> 第  2 、 3 、 4  行代码，每行都需要  1  个  unit_time  的执行时间，第  5 、 6  行代码循环执行了  n  遍，需要
>
> 2n * unit_time的执行时间，第7,8行执行了n^2遍，所以需要2n^2*unit_time的执行时间。所以整段代码执行时间
>
> T(n)=(2n^2+2n+3)*unit_time.
>
> 尽管我们不知道  unit_time  的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一
> 个非常重要的规律，那就是，所有代码的执行时间  T(n)  与每行代码的执行次数  n  成正比。
> 我们可以把这个规律总结成一个公式。
>
> 大O记号
>
> ![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190511161143.png)

> 其中， T(n)表示代码执行的时间； n  表示数据规模的大小； f(n)  表示每行代码执行的次数总和。因为这是一个公式，所以用  f(n)  来表示。公式中的O ，表示代码的执行时间  T(n)  与  f(n)  表达式成正比。
> 所以，第一个例子中的  T(n) = O(2n+2) ，第二个例子中的  T(n) = O(2n +2n+3) 。
>
> 这就是大  O  时间复杂度表示法。
>
> 大  O  时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（ asymptotic time complexity ），简称时间复杂度。
> 当  n  很大时，你可以把它想象成  10000 、 100000 。而公式中的低阶、常量、系数三部分并不左右增
> 长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大  O  表示法表示刚讲的
> 那两段代码的时间复杂度，就可以记为： T(n) = O(n) ；  T(n) = O(n ) 。

**时间复杂度分析**
如何分析一段代码的时间复杂度？有三个比较实用的方法。

1.  只关注循环执行次数最多的一段代码
大  O  这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，我们*在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了*。这段核心代码执行次数的  n的量级，就是整段要分析代码的时间复杂度。

那前面的第一个例子来说，其中第  2 、 3  行代码都是常量级的执行时间，与  n  的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第  4 、 5  行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了  n  次，所以总的时间复杂度就是  O(n)

2. 加法法则：总复杂度等于量级最大的那段代码的复杂度


    //前100个数相加
    int cal(int n) {
      int sum_1 = 0;
      int p = 1;
      for (; p < 100; ++p) {
        sum_1 = sum_1 + p;
      }
      //前n个数  
      int sum_2 = 0;
      int q = 1;
      for (; q < n; ++q) {
        sum_2 = sum_2 + q;
      }
    //
      int sum_3 = 0;
      int i = 1;
      int j = 1;
      for (; i <= n; ++i) {
        j = 1; 
        for (; j <= n; ++j) {
          sum_3 = sum_3 +  i * j;
        }
      }
    
      return sum_1 + sum_2 + sum_3;
    }


> 这个代码分为三部分，分别是求  sum_1 、 sum_2 、 sum_3 。我们可以分别分析每一部分的时间复杂
> 度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。
>
> 第一段的时间复杂度是多少呢？这段代码循环执行了  100  次，所以是一个常量的执行时间，跟  n  的
> 规模无关。
> 这里我要再强调一下，即便这段代码循环  10000  次、 100000  次，只要是一个已知的数，跟  n  无
> 关，照样也是常量级的执行时间。当  n  无限大的时候，就可以忽略。尽管对代码的执行时间会有很
> 大影响，但是**回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋**
> **势，所以不管常量的执行时间多大，我们都可以忽略掉。**因为它本身对增长趋势并没有影响。
> 那第二段代码和第三段代码的时间复杂度是多少呢？答案是  O(n)  和  O(n )。
>
> 综合三段代码的时间复杂度，我们取最大的量级，即总的复杂度为O(n^2)
>
> 也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽
> 象成公式就是：
> 如果  T1(n)=O(f(n)) ， T2(n)=O(g(n)) ；那么  T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n),g(n))).

3.乘法法则：嵌套代码的复杂度等于嵌套内外复杂度的乘积。

如果T1(n)=O(f(n)），T2(n)=O(g(n))；

那么T（n）=T1（n）xT2（n）=O(f(n))xO(g(n))=O(f(n)xg(n)).
也就是说，假设T1（n）=O（n），T2（n）=O（n^2），则T1（n）xT2（n）=O（n^3）。

落实到具体的代码上

    int cal(int n) {
      int ret = 0; 
      int i = 1;
      for (; i < n; ++i) {
        ret = ret + f(i);
      } 
    } 

    int f(int n) {
      int sum = 0;
      int i = 1;
      for (; i < n; ++i) {
        sum = sum + i;
      } 
      return sum;
    }


我们单独看cal（）函数。假设f()只是一个普通的操作，那第4~6行的时间复杂度就是，T1(n)=O(n)。

但f()函数本身不是一个简单的操作，它的时间复杂度是T2(n)=O(n)，所以，整个cal）函数的时间复杂度就是，T(n)=T1(n)xT2(n)=O(nxn)=O（n2）。



**常见的时间复杂度实例分析**

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190511172431.png)

**分类：**

多项式量级：

非多项式量级：O(2n)和O(n!)。

我们把复杂度为非多项式量级的算法问题叫做NP(Non-Deterministic Polynomial,非确定多项式)问题。

当数据规模n越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于NP时间复杂度问题略。

主要来看几种常见的多项式时间复杂度。

**1.O(1)**

常量级时间复杂度的一种表示方法，并不是指执行了一行代码。比如这段代码，即便有  3  行，它的时间复杂度也是  O(1 ），而不是  O(3) 。


    int i = 8;
    int j = 6;
    int sum = i + j;


由此，只要代码的执行时间不随  n  的增大而增长，这样代码的时间复杂度我们都记作O(1) 。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是 Ο(1)。

**2.O(logn),O(nlogn)**


    i=1;
    while (i <= n)  {
      i = i * 2;
    }


根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。
从代码中可以看出，变量  i  的值从  1  开始取，每循环一次就乘以  2 。当大于  n  时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量  i  的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190512170005.png)

所以，我们只要知道  x  值是多少，就知道这行代码执行的次数了。通过  2^x=n,则 x=log2n ，所以，这段代码的时间复杂度就是  O(log2n) 。
现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？


    i=1;
    while (i <= n)  {
      i = i * 3;
    }


由上得出这段代码的复杂度为O(log3n) 。

实际上，不管是以  2  为底、以  3  为底，还是以  10  为底，我们可以把所有对数阶的时间复杂度都记
为  O(logn)。

我们知道，对数之间是可以互相转换的，log3n就等于log32xlog2n，所以O(log3n)=O(C*log2n），其中C=log32是一个常量。基于我们前面的一个理论：**在采用大O标记复杂度的时候，可以忽略系数**，即O(Cf(n)=O(f(n))。所以，O（log2n）就等于O（log3n）。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为O（logn）。
如果你理解了我前面讲的O（logn），那O（nlogn）就很容易理解了。还记得我们刚讲的乘法法则吗？
如果一段代码的时间复杂度是O(logn)，我们循环执行n遍，时间复杂度就是O（nlogn）了。而且，O（nlogn）也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是O（nlogn）。

**3.O(m+n),O(m*n)**

这种情况代码的复杂度由两个数据的规模来决定。


    int cal(int m, int n) {
      int sum_1 = 0;
      int i = 1;
      for (; i < m; ++i) {
        sum_1 = sum_1 + i;
      }
      int sum_2 = 0;
      int j = 1;
      for (; j < n; ++j) {
        sum_2 = sum_2 + j;
      }
      return sum_1 + sum_2;
    }


从代码中可以看出， m  和  n  是表示两个数据规模。我们无法事先评估  m  和  n  谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是  O(m+n) 。
针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为： T1(m) + T2(n) = O(f(m) +
g(n)) 。但是乘法法则继续有效： T1(m)*T2(n) = O(f(m) * f(n)) 。

**空间复杂度分析**

时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度（ asymptotic space complexity ），**表示算法的存储空间与数据规模之间的增长关系。**


    void print(int n) {
      int i = 0;
      int[] a = new int[n];
      for (i; i <n; ++i) {
      a[i] = i * i;
      }
      for (i = n-1; i >= 0; --i) {
      print out a[i]
    }
    }


**跟时间复杂度分析一样，我们可以看到，第  2  行代码中，我们申请了一个空间存储变量  i ，但是它是**
**常量阶的，跟数据规模  n  没有关系，所以我们可以忽略。第  3  行申请了一个大小为  n  的  int  类型数**
**组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是  O(n)。**

常见空间复杂度： O(1) 、 O(n)、 O(n^2)

**小结：**

复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的
增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。

复杂度分析法则
1 ）单段代码看高频：比如循环。
2 ）多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。
3 ）嵌套代码求乘积：比如递归、多重循环等
4 ）多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。
常用的复杂度级别？
多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括，
O(1) （常数阶）、 O(logn) （对数阶）、 O(n) （线性阶）、 O(nlogn) （线性对数阶）、 O(n^2) （平
方阶）、 O(n^3) （立方阶）
非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。包括，
O(2^n) （指数阶）、 O(n!)

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190512173408.png)

**最好最坏及平均时间复杂度**


    // n  表示数组  array  的长度
    int find(int[] array, int n, int x) {
      int i = 0;
      int pos = -1;
      for (; i < n; ++i) {
        if (array[i] == x) 
            pos = i;
      }
      return pos;
    }


这段代码的功能是：长度为n的数组中，返回等于x的数组元素的下标，不等于则返回-1

缺点：全部元素遍历，不够高效

时间复杂度：O(n)


    // n  表示数组  array  的长度
    int find(int[] array, int n, int x) {
      int i = 0;
      int pos = -1;
      for (; i < n; ++i) {
        if (array[i] == x) {
          pos = i;
          break;
        }
      }
      return pos;
    }


优化后时间复杂度则由x出现的位置决定。最好第一个元素，最差最后一个元素。

最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，需要引入另一个概念：平均情况时间复杂度，后面我简称为平均时间复杂度。

例：

要查找的变量  x  在数组中的位置，有  n+1  种情况：在数组的  0 ～ n-1  位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以  n+1 ，就可以得到需要遍历的元素个数的平均值，

即：

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190513220835.png)

由大O记号表示可知，可以省略掉系数，低阶，常量，所以简化后的时间复杂度为O(n).

这个结论虽然是正确的，但是计算过程稍微有点儿问题。刚讲的这  n+1  种情况，出现的概率并不是一样的。我们知道，要查找的变量  x ，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，为了方便理解，我们假设在数组中与不在数组中的概率都为  1/2 。另外，要查找的数据出现在  0 ～ n-1  这  n  个位置的概率也是一样的，为  1/n 。所以，根据概率乘法法则，要查找的数据出现在  0 ～ n-1  中任意位置的概率就是 1/(2n).

因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190513221805.png)

这个值就是概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。
引入概率之后，前面那段代码的加权平均值为  (3n+1)/4 。用大  O  表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是  O(n) 。

由上可得：不是所有情况都要进行最好，最糟或平均时间复杂度的分析，量级相差较大时才进行区别。

**均摊时间复杂度**

例子：


    // array  表示一个长度为  n  的数组
    //  代码中的  array.length  就等于  n
    int[] array = new int[n];
    int count = 0;
    
    void insert(int val) {
        if (count == array.length) {
          int sum = 0;
          for (int i = 0; i < array.length; ++i) {
              sum = sum + array[i];
          }
          array[0] = sum;
          count = 1;
        }
        array[count] = val;
        ++count;
    }


代码功能：

往数组中插入数据的功能。

当数组满了之后，也就是代码中的  count == array.length  时，我们用  for  循环遍历数组求和，并清空数组，将求和之后的sum  值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。
最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为  count  的位置就可以了，所以最好情况时间复杂度为  O(1) 。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为  O(n)。

平均复杂度分析：

假设数组的长度是  n ，根据数据插入的位置的不同，我们可以分为  n  种情况，每种情况的时间复杂度是  O(1) 。除此之外，还有一种 “ 额外 ” 的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是  O(n) 。而且，这  n+1  种情况发生的概率一样，都是  1/(n+1) 。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190513224321.png)

这个例子不需要引入概率论的知识。这是为什么呢？我们先来对比一下这个  insert()  的例子和前面那个  find()  的例子，你就会发现这两者有很大差别。
首先， find()  函数在极端情况下，复杂度才为  O(1) 。但  insert()  在大部分情况下，时间复杂度都为O(1) 。只有个别情况下，复杂度才比较高，为  O(n) 。这是  insert() 第一个区别于  find()  的地方。
第二个不同的地方，对于  insert()  函数来说， O(1)  时间复杂度的插入和  O(n)  时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个  O(n)  插入之后，紧跟着  n-1  个  O(1)  的插入操作，循环往复。
所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。

因此引入了摊还分析法，通过摊还分析得到的时间复杂度叫做均摊时间复杂度。

**具体怎样使用摊还分析法分析算法的均摊时间复杂度？**

我们还是继续看在数组中插入数据的这个例子。每一次  O(n)  的插入操作，都会跟着  n-1  次  O(1)  的插入操作，所以把耗时多的那次操作均摊到接下来的  n-1  次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是  O(1) 。这就是均摊分析的大致思路。
均摊时间复杂度和摊还分析应用场景比较特殊，所以我们并不会经常用到。

**应用场景**

对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂
度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在
一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操
作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复
杂度。

一、复杂度分析的 4 个概念

最好情况时间复杂度：代码在最理想情况下执行的时间复杂度。

最坏情况时间复杂度：代码在最坏情况下执行的时间复杂度。

平均时间复杂度：用代码在所有情况下执行的次数的加权平均值表示。

均摊时间复杂度：在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级
别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结
果就等于低级别复杂度。

二、为什么要引入这 4 个概念？

1. 同一段代码在不同情况下时间复杂度会出现量级差异，为了更全面，更准确的描述代码的时间复
杂度，所以引入这 4 个概念。
2. 代码复杂度在不同情况下出现量级差别时才需要区别这四种复杂度。大多数情况下，是不需要区
别分析它们的。

三、

1. 平均时间复杂度
    代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。

2. 均摊时间复杂度
    两个条件满足时使用：

   1 ）代码在绝大多数情况下是低级别复杂度，只有极少数情况是高级别复杂度； 
   
     2 ）低级别和高级别复杂度出现具有时序规律。均摊结果一般都等于低级别复杂度。

**习题**


    //  全局变量，大小为  10  的数组  array ，长度  len ，下标  i 。
    int array[] = new int[10]; 
    int len = 10;
    int i = 0;
    //  往数组中添加一个元素
    void add(int element) {
      if (i >= len) { //  数组空间不够了
        //  重新申请一个  2  倍大小的数组空间
        int new_array[] = new int[len*2];
        //  把原来  array  数组中的数据依次  copy  到  new_array
        for (int j = 0; j < len; ++j) {
          new_array[j] = array[j];
        }
        // new_array  复制给  array ， array  现在大小就是  2  倍  len  了
        array = new_array;
        len = 2 * len;
      }
      //  将  element  放到下标为  i  的位置，下标  i  加一
      array[i] = element;
      ++i;
    }




线性表：

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190521161401.png)



非线性表：

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190521162302.png)

**数组**

1、存储结构：链式存储，前驱后继关联

2、操作：

crud(前后索引关联，涉及最优最糟问题)

特点：非常低效



查询操作：

了解其存储方式，即查询就是通过数组下标进行。



插入操作：

> 假设数组的长度为n，现在，如果我们需要将一个数据插入到数组中的第k个位置。为了把第k个位置腾出来，给新来的数据，我们需要将第k~n这部分的元素都顺序地往后挪一位。那插入操作的时间复杂度是多少呢？
>
> 如果在数组的末尾插入元素，那就不需要移动数据了，这时的(最优)时间复杂度为O（1）。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以**最坏时间复杂度**是O（n）。因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为（1+2+.n）/n=O（n）。

> 如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移k之后的数据。但是，**如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数组插入到第k个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第k位的数据搬移到数组元素的最后，把新的元素直接放入第k个位置。**
>
> 例：
>
> 假设数组a[10]中存储了如下5个元素：a，b，c，d，e。我们现在需要将元素X插入到第3个位置。我们只需要将c放入到a[5]，将a[2]赋值为X即可。最后，数组中的元素如下：a，b，x，d，e，c。
>
> ![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190521172005.png)

删除操作：

> 跟插入数据类似，如果我们要删除第k个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。
> 和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为O（1）；如果删除开头的数据，则最坏情况时间复杂度为O（n）；平均情况时间复杂度也为O（n）。

> 实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？
> 例：
>
> 数组a[1]中存储了8个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除a，b，c三个元素。
>
> 为了避免d，e，f，g，h这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

访问数组越界问题：

即访问数组以外的资源；



容器能否完全替代数组？

> 针对数组类型，很多语言都提供了容器类，比如Java中的Arraylist、C++STL中的ector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？
> ArrayList与数组相比，有哪些优势呢？
> ArrayList的优势就是可以将很多数组操作的细节封装起来。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是支持动态扩容。
> 数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为10的组，当第11个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。
>
> 注意
> 因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建ArrayList的时候事先指定数据大小。
>
> 例：
>

    ArrayList<User> users = new ArrayList(10000);
    for (int i = 0; i < 10000; ++i) {
      users.add(xxx);
    }


> 1.Java Arraylist无法存储基本类型，比如int、long，需要封装为Integer、Long类，而Autoboxing、Unboxing则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。
> 2.如果数据大小事先已知，并且对数据的操作非常简单，用不到ArrayList提供的大部分方法，也可以直接使用数组。
> 3.还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如Object[][] array；而用容器的话则需要这样定义：ArrayList<ArrayList>array。

数组下标问题：

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190521180349.png)

**链表：**

如何实现LRU缓存算法？

缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的CPU缓存、数据库缓存、浏览器缓存等等。

缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：

先进先出策略FIFO（First In，First Out）

最少使用策略LFU（Least Frequently Used）

最近最少使用策略LRU（Least Recently Used）。

数组与链表的存储结构：

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190522192439.png)

**单链表：**

特点：索引串联存储，除了存储数据外，还需存储下一节点的索引，头尾相连，最后一个元素指向空

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190522192803.png)

插入删除操作

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190522193530.png)

查找操作

链表要想随机访问第k个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。需要O（n）的时间复杂度。

**循环链表**

特点：同单链表，不同在于尾节点指向起始头节点。

优点：任意节点出发的操作，而不用从头开始。

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190522202553.png)

**约瑟夫环问题**

算法原理：

> 约瑟夫环运作如下：
>
> 1、一群人围在一起坐成 [2]  环状（如：N）
>
> 2、从某个编号开始报数（如：K）
>
> 3、数到某个数（如：M）的时候，此人出列，下一个人重新报数
>
> 4、一直循环，直到所有人出列 [3]  ，约瑟夫环结束
>
> 自己写了一个：[普通](https://www.cnblogs.com/fenqinearl/p/10910441.html)
>
> 看了下递归算法，还有待研究
>
> 优质推荐：[应有尽有](https://blog.csdn.net/never_cxb/article/details/49660191)

**双向链表**

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190523202501.png)

节点结构：前驱指针域	数据域	后继指针域

特点：

双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。

常见删除操作：

**删除结点中“值等于某个给定值”的结点；**
**删除给定指针指向的结点。**

对于第一种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过我前面讲的指针操作将其删除。
尽管单纯的删除操作时间复杂度是O（1），但遍历查找的时间是主要的耗时点，对应的时间复杂度为O（n）。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为O（n）。
对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点q需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到p->next=q，说明p是q的前驱结点。
但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要O（n）的时间复杂度，而双向链表只需要在O（1）的时间复杂度内就搞定了！

同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。
双向链表可以在O（1）时间复杂度搞定，而单向链表需要O（n）的时间复杂度。
除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置p，每次查询时，根据要查找的值与p的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。
现在，你有没有觉得双向链表要比单链表更加高效呢？这就是为什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉Java语言，你肯定用过LinkedHashMap这个容器。如果你深入研究LinkedHashMap的实现原理，就会发现其中就用到了双向链表这种数据结构。
实际上，这里有一个更加重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。

还是开篇缓存的例子。缓存实际上就是利用了空间换时间的设计思想。如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。所以我总结一下，**对于执行较慢的程序，可以通过消耗更多的内存（空间换时间）来进行优化；而消耗过多内存的程序，可以通过消耗更多的时间（时间换空间）来降低内存的消耗**。你还能想到其他时间换空间或者空间换时间的例子吗？
了解了循环链表和双向链表，如果把这两种链表整合在一起就是一个新的版本：**双向循环链表**。我想不用我多讲，你应该知道双向循环链表长什么样子了吧？你可以自己试着在纸上画一画。

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190523205433.png)

链表与数组性能比较

![](https://raw.githubusercontent.com/FenQingyang/Ey_PicBed/master/Images/.Net%E5%BC%80%E5%8F%9120190523211010.png)

> 不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。
> 数组简单易用，在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对CPU缓存不友好，没办法有效预读。
> 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。
> 你可能会说，我们Java中的ArayList容器，也可以支持动态扩容啊？我们上一节课讲过，当我们往支持动态扩容的数组中插入一个数据时，如果数组中没有空闲空间了，就会申请一个更大的空间，将数据拷贝过去，而数据拷贝的操作是非常耗时的。
> 我举一个稍微极端的例子。如果我们用ArrayList存储了了1GB大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，Arraylist会申请一个1.5GB大小的存储空间，并且把原来那1GB的数据拷贝到新申请的空间上。听起来是不是就很耗时？
>
> 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是Java语言，就有可能会导致频繁的GC（Garbage Collection，垃圾回收）。
> 所以，在我们实际的开发中，针对不同类型的项目，要根据具体情况，权衡究竟是选择数组还是链表。

解答开篇
好了，关于链表的知识我们就讲完了。我们现在回过头来看下开篇留给你的思考题。如何基于链表实现LRU缓存淘汰算法？
我的思路是这样的：

我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
1.如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
2.如果此数据没有在缓存链表中，又可以分为两种情况：·如果此时缓存未满，则将此结点直接插入到链表的头部；
·如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。
这样我们就用链表实现了一个LRU缓存，是不是很简单？
现在我们来看下m缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为O（n）。

实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到O（1）。因为要涉及我们还没有讲到的数据结构，所以这个优化方案，我现在就不详细说了，等讲到散列表的时候，我会再拿出来讲。
除了基于链表的实现思路，实际上还可以用数组来实现LRU缓存淘汰策略。如何利用数组实现LRU缓存淘汰策略呢？我把这个问题留给你思考。

课后思考
如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？相应的时间空间复杂度又是多少呢？

